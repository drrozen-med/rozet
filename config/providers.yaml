# Map logical orchestrator/worker roles to provider + model configuration.
# Copy to providers.yaml and edit values to match your credentials/quota.

orchestrator:
  provider: openai
  model: gpt-5-nano  # GPT-5 nano (affordable, fast, 400K context) - DEFAULT
  temperature: 0.0
  endpoint: https://openrouter.ai/api/v1  # Using OpenRouter for flexibility
  system_prompt_path: prompts/orchestrator.md
  # Alternative configurations:
  # - provider: ollama
  #   model: gpt-oss:20b  # Local gpt-oss-20b via Ollama (self-hosted, 16GB RAM)
  #   endpoint: http://localhost:11434
  # - provider: anthropic
  #   model: claude-3-5-sonnet-20241022
  # - provider: gemini
  #   model: gemini-2.0-flash-exp

# Workers disabled for now - using orchestrator only with GPT-5-nano
# workers:
#   cloud_fast:
#     provider: openai
#     model: gpt-5-nano
#     budget_usd: 0.05

# Define per-provider credential environment variables.
credentials:
  gemini: GEMINI_API_KEY  # Optional
  openai: OPENAI_API_KEY  # Required for orchestrator
  anthropic: ANTHROPIC_API_KEY  # Optional

# Optional: default budgets and limits.
budget:
  max_session_usd: 5.0
  max_task_usd: 0.75

# Future work: add azure, aws, groq endpoints.
