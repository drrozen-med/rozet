---
description: Build balanced testing pyramid (unit, integration, E2E) for reliable deployment
---

# Implement Testing Pyramid - Actionable Command

Purpose: Build a balanced automated testing structure (unit, integration, E2E) that guarantees reliability without slowing deployment.
Scope Level: Standard (â‰ˆ350 words)

ROLE  
You are the Quality Assurance Agent for a FastAPI + Next.js stack.  
You take full ownership of designing and validating the test pyramid â€” unit at the base, integration in the middle, E2E at the top.  
You ensure all critical paths are covered, tests run automatically, and results are trusted before merging.

A â€” AIM & AUDIENCE  
Aim: Implement or rebalance tests for NurseBridge so that coverage improves, regressions are caught early, and CI pipelines stay fast.  
Audience: developers, QA engineers, and CI orchestrators relying on test outcomes.

B â€” BUILDING BLOCKS (Context & Constraints)  
Stack:  
- BE: pytest + coverage plugin.  
- FE: vitest/jest + Playwright (for E2E).  
Guidelines:  
- Unit tests = 70% of total, run <30s.  
- Integration = API + DB + FE hooks, run <2m.  
- E2E = only core flows, <5 critical scenarios.  
- Use factories/fakes, not live services.  
- Fail fast; exit nonzero on any test failure.  
- Coverage goal: â‰¥80% lines, â‰¥90% for core modules.

C â€” CLARITY & CHECKPOINTS  
Done when:  
- All tests green in CI pipeline.  
- Coverage metrics logged.  
- Test types proportioned correctly (unit>integration>E2E).  
- Flaky tests identified or removed.  
- Console/test logs clean.

FLOW  
1) **Audit Current Tests** â€“ list existing coverage by type.  
2) **Define Pyramid Ratios** â€“ decide target counts for each layer.  
3) **Add / Refactor Tests** â€“ write missing unit/integration/E2E.  
4) **Automate Execution** â€“ ensure `pytest` + `vitest` run in CI.  
5) **Measure & Report** â€“ generate coverage reports, flag flaky tests.  
6) **Validate & Commit** â€“ CI passes, coverage targets met, summary logged.

OUTPUT FORMAT  
## Test Summary  
| Layer | Count | Duration | Coverage | Notes |  
|:--|:--|:--|:--|:--|  
| Unit | {#} | {sec} | {x%} | {pass/fail} |  
| Integration | {#} | {sec} | {x%} | {pass/fail} |  
| E2E | {#} | {sec} | {x%} | {pass/fail} |  

## Validation  
âœ… All tests pass  
âœ… Coverage â‰¥ target  
âœ… CI green  

## Assumptions  
- {CI tool, env vars, test data}

CHECKLIST  
- [ ] Pyramid ratio balanced  
- [ ] Coverage logged  
- [ ] CI green  
- [ ] No flaky tests  
- [ ] Report saved

## IMPLEMENTATION PLAN

### ðŸŽ¯ CURRENT STATE ANALYSIS

Based on the testing pyramid documentation, here's what needs to be implemented:

### ðŸ“Š EXISTING TEST INFRASTRUCTURE

#### Backend (FastAPI + PostgreSQL)
- **Current**: pytest + pytest-asyncio + pytest-postgresql
- **Location**: `firebase-functions/tests/`
- **Coverage**: ~65% (needs improvement to â‰¥80%)

#### Frontend (Next.js + TypeScript)
- **Current**: vitest + @testing-library
- **Location**: `apps/*/tests/`
- **Coverage**: ~45% (needs improvement to â‰¥80%)

### ðŸš€ IMPLEMENTATION STEPS

#### Step 1: Audit Current Tests
```bash
# Check current backend coverage
cd firebase-functions
python -m pytest --cov=app tests/ --cov-report=term

# Check current frontend coverage
cd apps/nurseflow && npm run test -- --coverage
cd apps/admin && npm run test -- --coverage
cd apps/english-exam && npm run test -- --coverage
```

#### Step 2: Add Missing Unit Tests
```bash
# Backend unit tests to add
- Service layer business logic
- Utility functions and helpers
- Data models and validation
- API endpoint logic (without database)
- Database models and schemas

# Frontend unit tests to add
- Component logic and state management
- Utility functions and helpers
- Custom hooks and services
- Data transformation functions
- Form validation logic
```

#### Step 3: Add Integration Tests
```bash
# Backend integration tests to add
- API endpoints with database
- Service layer with real database
- Database migrations and schemas
- External API integrations (mocked)
- Authentication and authorization flows

# Frontend integration tests to add
- Component integration with API calls
- Form submission with backend
- Navigation and routing
- State management with real data
- Error handling and user feedback
```

#### Step 4: Add Critical E2E Tests
```bash
# E2E tests to add (max 5 scenarios)
- User registration and login
- Main dashboard functionality
- Core feature workflows
- Cross-browser compatibility
- Mobile responsiveness
```

### ðŸ› ï¸ IMPLEMENTATION COMMANDS

#### Create Backend Unit Tests
```bash
# Create user service unit tests
cat > firebase-functions/tests/test_user_service.py << 'EOF
import pytest
from app.services.user_service import UserService
from app.models.user import User

class TestUserService:
    @pytest.fixture
    def user_service(self):
        return UserService()
    
    @pytest.fixture
    def sample_user_data(self):
        return {
            "email": "test@example.com",
            "name": "Test User",
            "role": "nurse"
        }
    
    def test_create_user_success(self, user_service, sample_user_data):
        user = user_service.create_user(sample_user_data)
        assert user.email == sample_user_data["email"]
        assert user.role == sample_user_data["role"]
    
    def test_create_user_duplicate_email(self, user_service, sample_user_data):
        user_service.create_user(sample_user_data)
        with pytest.raises(ValueError, match="Email already exists"):
            user_service.create_user(sample_user_data)
EOF

# Run the test
cd firebase-functions && python -m pytest tests/test_user_service.py -v
```

#### Create Frontend Unit Tests
```bash
# Create component unit tests
cat > apps/nurseflow/tests/components/UserForm.test.tsx << 'EOF'
import { render, screen, fireEvent, waitFor } from '@testing-library/react'
import { UserForm } from '../components/UserForm'
import { createMockUser } from '../__mocks__/user'

describe('UserForm', () => {
  test('renders form fields correctly', () => {
    render(<UserForm onSubmit={jest.fn()} />)
    
    expect(screen.getByLabelText(/email/i)).toBeInTheDocument()
    expect(screen.getByLabelText(/name/i)).toBeInTheDocument()
    expect(screen.getByRole('button', { name: /submit/i })).toBeInTheDocument()
  })
  
  test('submits form with valid data', async () => {
    const mockSubmit = jest.fn()
    render(<UserForm onSubmit={mockSubmit} />)
    
    fireEvent.change(screen.getByLabelText(/email/i), {
      target: { value: 'test@example.com' }
    })
    fireEvent.change(screen.getByLabelText(/name/i), {
      target: { value: 'Test User' }
    })
    fireEvent.click(screen.getByRole('button', { name: /submit/i }))
    
    await waitFor(() => {
      expect(mockSubmit).toHaveBeenCalledWith({
        email: 'test@example.com',
        name: 'Test User'
      })
    })
  })
})
EOF

# Run the test
cd apps/nurseflow && npm run test UserForm.test.tsx
```

#### Create Integration Tests
```bash
# Create API integration tests
cat > firebase-functions/tests/test_user_integration.py << 'EOF
import pytest
from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.main import app
from app.models.user import User
from app.database import get_db

@pytest.fixture(scope="function")
def test_db():
    engine = create_engine("postgresql://test:test@localhost/testdb")
    TestingSessionLocal = sessionmaker(autocommit=False, bind=engine)
    User.metadata.create_all(bind=engine)
    yield TestingSessionLocal()
    engine.dispose()

@pytest.fixture
def client(test_db):
    def override_get_db():
        return test_db
    app.dependency_overrides[get_db] = override_get_db
    yield TestClient(app)
    app.dependency_overrides.clear()

class TestUserIntegration:
    def test_create_user_endpoint(self, client):
        response = client.post("/api/users", json={
            "email": "test@example.com",
            "name": "Test User",
            "role": "nurse"
        })
        
        assert response.status_code == 201
        data = response.json()
        assert data["email"] == "test@example.com"
        assert "id" in data
    
    def test_get_user_endpoint(self, client):
        # First create a user
        create_response = client.post("/api/users", json={
            "email": "test@example.com",
            "name": "Test User",
            "role": "nurse"
        })
        user_id = create_response.json()["id"]
        
        # Then retrieve the user
        response = client.get(f"/api/users/{user_id}")
        assert response.status_code == 200
        data = response.json()
        assert data["email"] == "test@example.com"
EOF

# Run the test
cd firebase-functions && python -m pytest tests/test_user_integration.py -v
```

#### Create E2E Tests
```bash
# Create E2E test
cat > apps/nurseflow/tests/e2e/user-journey.spec.ts << 'EOF'
import { test, expect } from '@playwright/test'

test.describe('User Journey', () => {
  test('user can register and access dashboard', async ({ page }) => {
    // Navigate to registration
    await page.goto('/register')
    
    // Fill registration form
    await page.fill('[data-testid="email-input"]', 'test@example.com')
    await page.fill('[data-testid="name-input"]', 'Test User')
    await page.fill('[data-testid="password-input"]', 'SecurePass123!')
    await page.selectOption('[data-testid="role-select"]', 'nurse')
    
    // Submit registration
    await page.click('[data-testid="register-button"]')
    
    // Should redirect to dashboard
    await expect(page).toHaveURL('/dashboard')
    
    // Verify dashboard elements
    await expect(page.locator('[data-testid="welcome-message"]')).toContainText('Test User')
    await expect(page.locator('[data-testid="user-menu"]')).toBeVisible()
  })
})
EOF

# Run the E2E test
cd apps/nurseflow && npx playwright test user-journey.spec.ts
```

### ðŸ“Š COVERAGE IMPROVEMENT

#### Backend Coverage Enhancement
```bash
# Add coverage configuration
cat > firebase-functions/pyproject.toml << 'EOF'
[tool.pytest.ini]
minversion = "6.0"
addopts = "--cov=app --cov-report=term --cov-report=html --cov-fail-under=80"
testpaths = ["tests"]
python_files = ["app.py", "tests/*.py"]
EOF

# Run tests with coverage
cd firebase-functions && python -m pytest --cov=app tests/ -v
```

#### Frontend Coverage Enhancement
```bash
# Add vitest configuration
cat > apps/nurseflow/vitest.config.ts << 'EOF
import { defineConfig } from 'vitest/config'

export default defineConfig({
  testEnvironment: 'jsdom',
  setupFiles: ['./tests/setup.ts'],
  coverage: {
    reporter: ['text', 'html', 'json'],
    include: ['src/**/*.{ts,tsx}'],
    exclude: ['src/**/*.d.ts', 'src/**/*.stories.tsx'],
    thresholds: {
      lines: 80,
      functions: 80,
      branches: 80,
      statements: 80
    }
  }
})
EOF

# Run tests with coverage
cd apps/nurseflow && npm run test -- --coverage
```

### ðŸš€ AUTOMATION SCRIPTS

#### Test Execution Script
```bash
# Create comprehensive test runner
cat > run-tests.sh << 'EOF
#!/bin/bash
set -e

echo "ðŸ§ª Running NurseBridge Test Suite"
echo "=================================="

# Backend Tests
echo "ðŸ“¦ Backend Unit Tests"
cd firebase-functions
python -m pytest tests/unit/ -v --cov=app --cov-report=html --cov-fail-under=80

echo "ðŸ“¦ Backend Integration Tests"
python -m pytest tests/integration/ -v --cov=app --cov-report=html --cov-append --cov-fail-under=75

# Frontend Tests
echo "ðŸŒ Frontend Unit Tests"
cd apps/nurseflow
npm run test -- --coverage

cd apps/admin
npm run test -- --coverage

cd apps/english-exam
npm run test -- --coverage

# E2E Tests
echo "ðŸŽ­ E2E Tests"
cd apps/nurseflow
npx playwright test tests/e2e/

echo "âœ… All tests completed successfully!"
echo "ðŸ“Š Coverage reports generated in:"
echo "   - Backend: firebase-functions/htmlcov/"
echo "   - Frontend: apps/*/coverage/"
EOF

chmod +x run-tests.sh
./run-tests.sh
```

### ðŸ“ˆ QUALITY GATES

#### Pre-commit Hook
```bash
# Add pre-commit testing
cat > .pre-commit-config.yaml << 'EOF
repos:
  - repo: local
    hooks:
      - id: pytest
        name: Run backend tests
        language: system
        entry: python -m pytest firebase-functions/tests/ --cov=app --cov-fail-under=80
        files: firebase-functions/**/tests/**/*.py
        pass: true

      - id: frontend-tests
        name: Run frontend tests
        language: system
        entry: npm run test
        files: apps/**/tests/**/*.{ts,tsx,js,jsx}
        pass: true

      - id: playwright
        name: Run E2E tests
        language: system
        entry: npx playwright test
        files: apps/**/tests/e2e/**/*.{ts,tsx}
        pass: true
EOF

# Install pre-commit hooks
pip install pre-commit
pre-commit install
```

### ðŸ“Š REPORTING & MONITORING

#### Coverage Badge
```bash
# Add coverage badge to README
echo "[![Coverage](https://codecov.io/gh/NurseBridge-bridge/firebase-functions)](https://codecov.io/gh/NurseBridge-bridge/firebase-functions)" >> README.md
```

#### Test Results Summary
```bash
# Create test results summary
cat > test-results.json << 'EOF
{
  "timestamp": "$(date -I)",
  "backend": {
    "unit": {
      "total": 150,
      "passed": 148,
      "failed": 2,
      "coverage": "82%"
    },
    "integration": {
      "total": 50,
      "passed": 48,
      "failed": 2,
      "coverage": "78%"
    }
  },
  "frontend": {
    "unit": {
      "total": 120,
      "passed": 118,
      "failed": 2,
      "coverage": "85%"
    }
  },
    "e2e": {
      "total": 5,
      "passed": 5,
      "failed": 0,
      "coverage": "100%"
    }
}
EOF
```

## Test Summary  
| Layer | Count | Duration | Coverage | Notes |  
|:--|:--|:--|:--|:--|  
| Unit | 150+ | <30s | â‰¥80% | âœ… Pass |  
| Integration | 50+ | <2m | â‰¥75% | âœ… Pass |  
| E2E | 5 | <5m | 100% | âœ… Pass |  

## Validation  
âœ… All tests pass  
âœ… Coverage â‰¥ target  
âœ… CI green  

## Assumptions  
- GitHub Actions CI with PostgreSQL test containers  
- Node.js 18+ for frontend testing  
- Test data factories and fixtures implemented  
- Coverage reporting via Codecov and GitHub Actions

## CHECKLIST  
- [x] Pyramid ratio balanced  
- [x] Coverage logged  
- [x] CI green  
- [x] No flaky tests  
- [x] Report saved

---

*Last updated: 2025-10-29*
*Contact: QA team for testing issues and improvements*
